\documentclass[11pt]{article}
\usepackage[a4paper]{geometry}
\usepackage{naaclhlt2015}
%\usepackage{times}
\usepackage{url}
%\usepackage{latexsym}
\usepackage{amsmath}
%\usepackage{amsfonts}
%\usepackage{amssymb}
\usepackage{color}
\usepackage{arydshln}

\usepackage{graphicx}
\usepackage{xspace}
\usepackage{multirow}

%\setlength\titlebox{5cm}

\title{Model Invertibility Regularization:\\Sequence Alignment With or Without Parallel Data}
%\author{First Author \\
%  Affiliation / Address line 1 \\
%  Affiliation / Address line 2 \\
%  Affiliation / Address line 3 \\
%  {\tt email@domain} \\\And
%  Second Author \\
%  Affiliation / Address line 1 \\
%  Affiliation / Address line 2 \\
%  Affiliation / Address line 3 \\
%  {\tt email@domain} \\}
%\date{}

\input{math_definition.tex}

\usepackage{txfonts}

\begin{document}
\maketitle
\begin{abstract}
We present Model Invertibility Regularization (\method{MIR}), a method for jointly training two directional word alignment models
that relies on the simple intuition that the back-translation of a translation should likely be itself.
By coupling the two models through their parameters (as opposed to through their inferences, as in Liang et al.'s Alignment by Agreement (ABA) method), our method remains applicable to all IBM-style alignment models and as well as to alignment without parallel data.
Our proposed algorithm is mathematically sound and enjoys the convergence guarantees of EM.
We tested \method{MIR} on two tasks:
(1)~On Czech-English and Chinese-English word alignment, our method attains significant F- and BLEU score improvements compared to both GIZA++ and \method{ABA}.
(2)~On Japanese-to-English back-transliteration without parallel data, applied to the decipherment model of Ravi and Knight, \method{MIR} learns sparser models that close the gap in whole-name error rate by 33\% relative to a model trained on parallel data, and significantly beats a previous approach by Mylonakis et al.

%In "Alignment by Agreement" (ABA) Liang. et al. propose to train two directional word alignment models by maximizing their joint data-likelihood and a term that measures their inferences agreements.
%Inspired by their method, we develop a joint training approach for general sequence alignment that relies on the simple intuition that a back-translation of a translation should likely be itself.
%By coupling the two models through their parameters (as opposed to through their inferences) our method remains applicable to all word-based alignment models and furthermore extends to alignment \emph{without} parallel data.
%Our proposed algorithm is mathematically sound and enjoys convergence guarantees by virtue of generalized EM.
%We test our method on two sequence alignment tasks:
%(1) On Czech-English and Chinese-English our method attains significant F- and BLEU score improvements compared to both giza++ and ABA.
%(2) On Japanese-to-English back-transliteration without parallel data, our method, applied to the decipherment model of Ravi and Knight, learns sparser models that reduce whole-name error rate by 33\% relative to a model trained on parallel data, as well as significantly beats a previous approach by Markos et al.


%Transferring information (such as words or sentences) from a source to target language is a natural language phenomenon that is intuitively invertible - the translation of the translation of an entity is likely to be itself.
%In NLP however, the commonplace generative models describing such phenomena are directional, 
%Left unchecked, independently training two such directional models often leads to trained models that diverge from 

%Sequence alignment is a key problem in NLP (e.g., word alignment on parallel text).
%Common alignment models are based on a directed generative story which views one sequence as a source, and the other, as being generated a source a source sequence into a target sequence, even though the phenomenon being modeled is itself invertible (translation, transliteration)
%%For example, combining word alignments in both directions leads to improved results.
%We propose a method for jointly learning bi-directional alignment models by maximizing their likelihoods, coupled  a measure of model agreement.
%In contrast to the Alignment by Agreement approach of Liang et al., our method works even \emph{without} parallel data 
%We test our method on two tasks:
%(1) On Czech-English and Chinese-English word alignment, 
%we gain +0.4--0.5 \bleu compared to GIZA++. 
%Combining with alignments from Liang et al.'s model brings the total improvement to +0.7--1.5 \bleu
%(2) On Japanese-to-English back-transliteration \emph{without} parallel data, our method, applied to the decipherment model of Ravi and Knight, learns sparser models that reduce whole-name error rate, relative to a model trained on parallel data, by 33\%.
\end{abstract}

\section{Introduction}
\label{sec:introduction}
\input{introduction.tex}

\section{Background}
\label{sec:background}
\input{background.tex}

\section{Model Invertibility Regularization}
\label{sec:method}
\input{method.tex}

\section{Baselines and Related Work}
\label{sec:related}
\input{related.tex}

\section{Word Alignment and MT Experiments}
\label{sec:alignment}
\input{alignment.tex}

\section{Transliteration Deciphering Experiment}
\label{sec:transliteration}
\input{transliteration.tex}


\section{Conclusion}
We presented Model Invertibility Regularization (\method{MIR}), an unsupervised method for jointly training two bidirectional sequence alignment models with or without parallel data.
Our formulation is based on the simple observation that the alignment tasks at hand are inherently invertible and encourages the translation tables in both models to behave more like pseudo-inverses of each other.

We derived an efficient, theoretically sound EM algorithm and demonstrated our method's effectiveness on two different alignment tasks. On word alignment, \method{MIR} yielded \bleu improvements comparable to the Alignment by Agreement method \cite{liang+:2006:align}, and orthogonal in the sense that combining the two methods yielded further improvement (up to 1.5 \bleu). On Japanese-English back-transliteration without parallel data, we obtain significant error rate reduction beating two baseline methods \cite{RK09,Mylonakis2007}. 

As future work, we will consider applying $\method{MIR}$ on large-scale MT decipherment \cite{Ravi11,Dou13}, where, so far, only a single directional model has been used.
%\section*{Appendix}
%To prove $h(x,y) = \sqrt{xy}$ is concave over $x,y\in [0,1]$, we show $h(\alpha (x_0, y_0) + (1-\alpha)(x_1, y_1)) \ge \alpha h(x_0,y_0) + (1-\alpha) h(x_1, y_1)$:
%\begin{align*}
%&h^2(\alpha (x_0, y_0) + (1-\alpha)(x_1, y_1)) \\
%&= (\alpha x_0 + (1-\alpha) x_1)(\alpha y_0 + (1-\alpha) y_1) \\
%&\ge \left( \alpha \sqrt{x_0 y_0} + (1-\alpha) \sqrt{x_1 y_1} \right)^2 \\
%&= \left( \alpha h(x_0,y_0) + (1-\alpha) h(x_1,y_1) \right)^2
%\end{align*}
%with the inequality following from the Cauchy-Schwarz inequality.

%We have presented Parameter Agreement Training (PAT) - an approach for jointly training two conditional models that encourages agreement on parameter values.
%We derived an optimization procedure based on the EM framework, and argued that it is efficiently solvable due to the concavity of our agreement regularizer.
%In contrast to previous work on agreement training, we have demonstrated that our approach can be successfully applied even without parallel data.
\bibliographystyle{naaclhlt2015}
\bibliography{thesis}

\end{document}

%%%% old content of abstract / introduction
%	\iffalse
%% this doesn't make a lot of sense
%We present a simple approach that encourages jointly trained conditional models to agree on their parameter values. In contrast to methods that encourage agreement on inferences, our method can be applied in a wider range of settings.
%We demonstrate that our method, called parameter agreement training, leads to state-of-the-art accuracies on word alignment, and significantly improves accuracy on back-transliteration with no parallel data -- almost halving the difference between the previous best method and using parallel data.

%Alignment is a crucial subtask for many larger NLP problems: Word alignments are the backbone for extracting translation rules used in statistical machine translation; phoneme alignments are used to transliterate Japanese katakana to English and vice-versa. The goal is to align entities, which could be words or phonemes, between two sequences, which could be pairs of source and target sentences or pairs of phoneme sequences. The popular models used in these tasks are both \emph{generative} and \emph{directed}, that is, they define a directed sequence of events by which one side of the pair produces the other side. For example, the IBM models for word alignment \newcite{brown+alii:1993} describe a stochastic process by which the target sentence is generated from the source sentence via word alignments. These processes can sometimes produce different alignments, depending on the direction of generation. The generative process for word alignment allows a target word to align to \emph{at most} one source word, producing different alignments in the source-target vs target-source directions. Additionally, the models in each direction are typically trained independently of each other. As a result, they disagree on the alignments they predict and different errors can arise in each direction. To remedy this, we resort to ad-hoc alignment symmetrization approaches \cite{koehn+:2003} \emph{after} training. A second problem for training alignment models is the need for parallel data. For example, in \newcite{KG98}, the authors use (some number) \marginpar{insert number} of parallel English-Katana sequences to training phoneme alignment models. While large amounts of parallel data needed for word alignment is readily available for many language pairs, acquiring parallel phoneme sequences for transliteration can be very challenging. 
%
%There has been previous work on solving the problem of model disagreement in word alignment \cite{liang+:2006:align} and training phoneme alignment models from large amounts of monolingual data~\cite{RK09}. However, they do not optimize a clear objective function and their approach cannot be applied to training alignment models without parallel data. ~\newcite{RK09} alleviate the reliance on parallel data and improve monolingual phoneme alignment over the baseline, but their approach does not encourage model agreement, which can improve alignment accuracy. In our paper, we present a \emph{single} approach that achieves both model agreement during training, and can be used in non-parallel settings. Our approach, \emph{Parameter Agreement Training}, encourages model agreement by adding a regularization term that penalizes disagreement between the (magnitudes of the ?) model parameters in each direction. Our regularizer is convex, allowing us to efficiently optimize the objective function with the EM algorithm. We apply our techniques to word alignment and phoneme alignment. Using our approach, we are able to significantly improve over \newcite{RK09}. In word alignment, our results compare favorably with results from previous approaches for model agreement.  
%\fi
