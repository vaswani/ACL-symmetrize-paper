%Given a \emph{target} French sentence, $\mathbf{f_{1}^{J}} =  f_{1}, f_{2}, \ldots , f_{j}, \ldots, f_{J}$, and a \emph{source} English sentence, $\mathbf{e_{1}^{I}} =  e_{1}, e_{2}, \ldots , e_{i}, \ldots, e_{I}$, word alignment models describe the generative process by which the source sentence creates the target ($E \rightarrow F$) ausing latent alignments $\mathbf{a_{1}^{J}} = a_{1}, a_{2}, \ldots , a_{j}, \ldots, a_{J}$. The alignment variable $a_{j}$ specifies the English word $e_{a_{j}}$ that the French word $f_j$ is aligned to. 
%
%The IBM Models 1--2 and the HMM alignment models have two sets of parameters, the translation probabilities $P_{t}(f_{j} \mid e_{a_{j}})$ and distortion probabilities, $P_{d}(a_{j}\mid a_{j-1},j)$. These models differ in their implementation and estimation of the distortion probabilities, but share the same translation probabilities. The general form of the joint probability  of a target sentence and alignment given the source sentence is:
%
%\begin{equation} \label{eq:joint-prob-align}
%P(\mathbf{f_{1}^{J}}, \mathbf{a_{1}^{J}} \mid \mathbf{e_{1}^{I}})  = \prod_{j=1}^{J} P_{d}(a_{j}\mid a_{j-1},j) P_{t}(f_{j} \mid e_{a_{j}})
%\end{equation}
%
%During training, we typically estimate the parameters that maximize 
%\begin{equation}
%\log \sum_{a_{1}^{J}}  P(\mathbf{f_{1}^{J}}, \mathbf{a_{1}^{J}} \mid \mathbf{e_{1}^{I}}) = \log P(\mathbf{f_{1}^{J}} \mid \mathbf{e_{1}^{I}})
%\end{equation}.
%
%For details on parameter estimation of these models, and how to deal with empty words, the reader can refer to ~\newcite{och+ney:2003}. For translation, we use the \emph{Viterbi} alignments, 
%\begin{equation}
%\hat{\mathbf{a_{1}^{J}}} = \argmax_{\mathbf{a_{1}^{J}}} P(\mathbf{f_{1}^{J}}, \mathbf{a_{1}^{J}} \mid \mathbf{e_{1}^{I}})
%\end{equation}
%The generative story allows each target word $f_{j}$ to align to only one source word $e_{a_j}$. This can be problematic when the target language has compound words that must align to two or more source language words. The standard solution is to train another model in the \emph{reverse} direction ($F \rightarrow E$), $P(\mathbf{e_{1}^{L}}, \mathbf{a_{1}^{L}} \mid \mathbf{f_{1}^{J}})$ and then symmetrize the Viterbi alignments in both directions using heuristics like \emph{grow-diag-final}  ~\cite{koehn+:2003}. Symmetrization remedies some of the mistakes that the independently trained models make, garbage collection in particular ~\cite{liang+:2006:align}. However, the $E \rightarrow F$ and  $F \rightarrow E$ models do not communicate during training, which could guide the parameters in the wrong direction. In ~\newcite{liang+:2006:align} and ~\newcite{ganchev2010posterior}, the authors show that training the alignment models jointly can improve alignment quality. In ~\newcite{liang+:2006:align}, the authors encourage the probabilities over alignments in each direction to agree, per sentence pair. However, this renders the inference intractable and the authors have to resort to an approximation, without specifying the objective that the approximate procedure ends up optimizing. In contrast, we optimize a clear objective which improves in every iteration. In ~\newcite{ganchev2010posterior}, the authors optimize a clear objective which encourages agreement between the alignments. However, their optimization procedure is expensive and scaling to large datasets is a challenge. \marginpar{need to make sure that it doesn't scale. I suspect it doesn't}.
%
%
%\begin{table}[h]
%\begin{center}
%\begin{tabular}{|c|c|c|c|}
%\cline{2-4} 
%\multicolumn{1}{c|}{} & de-en & cz-en & $\PP > 0.01$\tabularnewline
%\hline 
%~\newcite{liang+:2006:align}  & $71$\% & $70$\%  & -\tabularnewline
%\hline 
%PAT (our) & $71$\% & $69$\%  & -\tabularnewline
%\hline 
%\end{tabular}
%\label{tbl:Alignment Results}
%\caption{Alignment F-score improves.}
%\end{center}
%\end{table}

To test the effectiveness of parameter agreement training, we carried out Czech to English and Chinese to English translation experiments, comparing standard EM training, ABA training, and PAT. 

\begin{table*}
\begin{center} \small
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{cc|c|l|l|l|lll}
task & data (M) & system & align F1 (\%)  &\multicolumn{3}{c}{\bleu (\%)} \\
     &      &        &             & 2008 & 2009 & 2010 \\
\hline
\multirow{3}{*}{Chi-Eng} & \multirow{3}{*}{5.3+6.6} & baseline & 64.6  &  23.6 & & \\
        &       & PAT &  70.9 (+6.3) & 24.0 (+0.4) & &  \\
        &       & ABA  & 70.8 (+6.2)& 24.4 (+0.8) & \\
        &       & ABA+PAT  &    & 25.1 (+1.5) & \\
\hline
\multirow{3}{*}{Cze-Eng} & \multirow{3}{*}{1.6+1.8} & baseline & 65.0 & & 16.7 & 17.1  \\
        &       & PAT   & 69.6 (+4.6)& & 17.1 (+0.4)& 17.6 (+0.5)& \\
        &       & ABA    & 70.4 (+5.4) & & 17.1 (+0.4)&  17.7  (+0.6) &\\
        &       & ABA+PAT   &  & &  17.4 (+0.7)& 17.9 (+0.8)&
\end{tabular}
\end{center}
\caption{For Czech-English, the year refers to the WMT shared task; for Chinese-English, the year refers to the NIST Open MT Evaluation.}
\label{tab:results}
\end{table*}


\subsection{Training}
Following standard practice, we first trained our word alignment models on the following parallel data:
\begin{itemize}
\item \textbf{Chinese-English}: selected data from the constrained task of the NIST 2009 Open MT Evaluation.
\item \textbf{Czech-English}: selected data from the Czech-English News Commentary corpus.
\end{itemize} 

For both ABA and vanilla EM training, we used the publicly available word alignment toolkits that implement them. GIZA++, the popular word alignment toolkit\footnote{https://code.google.com/p/giza-pp/}, implements EM training of the IBM and HMM alignment models, and the toolkit for for ABA \footnote{http://cs.stanford.edu/~pliang/software/cross-em-aligner-1.3.zip} trains IBM Model~1 and the HMM word alignment model. For both our baseline approaches and PAT, we ran experiments, one with $n$ iterations of Model~1 followed by  $n$ iterations of the HMM alignment model, where $n={5,10}$. We trained word alignment models in both directions for both language pairs, and symmetrized our alignments with \emph{posterior decoding}, as described in \newcite{liang+:2006:align}. We will go over the details of posterior decoding in Section~\ref{sec:pos-decoding}.

\subsubsection{Parameter Agreement Training For Word Alignment}
As described in section~\ref{subsec:optimization}, in the E-step, we compute the posterior distribution over alignments in each direction, which amounts to computing the expected counts  $E_1[C(e,f)] $ and $E_2[C(e,f)] $, where $C(e,f)$ is the number of times $e$ is seen aligned to $f$. In the M-step, we use the expected counts to restimate model parameters by maximizing the regularized expected complete data log likelihood. In our work, we only encourage agreement between the translation probabilities $t(e \mid f)$ and $t(f \mid e)$, and leave PAT for the distortion parameters for future work. The estimation of the distortion probabilities is thus left unchanged. The objective function in the M-step for the translation probabilities is 

\begin{align*}
&\sum_{e,f} \Bigl(  E_1[C(e,f)] \log t(e \mid f)  + \\ 
&E_2[C(e,f)] \log t(f \mid e) + \sqrt{t(e \mid f)t(f \mid e)} \Bigr), 
\end{align*}

\noindent
which is maximized with projected gradient descent. 

\subsection{Prediction With Posterior Decoding} \label{sec:pos-decoding}
Word alignments are used downstream in the machine translation pipeline to learn translation rules. Having trained our alignment models, we have to predict word alignments for the sentence pairs in our bilingual corpus. By combining the posterior probabilities of the alignments from the models in each direction, \newcite{liang+:2006:align} present two decoding approaches for predicting word alignments:

\begin{itemize}
\item \textbf{D1}: For every sentence pair $(\mathbf{e},\mathbf{f})$, for each direction $k=\{1,2\}$, keep an alignment $a_j $ if $p(a_j \mid \mathbf{e},\mathbf{f},\Theta_k) \ge \delta$, where $\delta$ is a threshold that controls the tradeoff between precision and recall, and $0< \delta < \infty$. By taking the union or intersection of the alignments in each direction, we can obtain single alignments for $(\mathbf{e},\mathbf{f})$.
\item \textbf{D2}: For each sentence pair $(\mathbf{e},\mathbf{f})$, multiply the marginals for the alignments in each direction and and keep the alignments that pass a threshold, that is, keep the alignments $a_j$ for which  $p(a_j \mid \mathbf{e},\mathbf{f},\Theta_1) p(a_j \mid \mathbf{e},\mathbf{f},\Theta_2) \ge \delta$. 
\end{itemize}

For ABA, we used \textbf{D1}, the default decoding approach provided by the toolkit. For vanilla EM training and PAT, we  experimented with both \textbf{D1} and \textbf{D1}, optimizing for alignment F-score on a validation set. 

\subsection{Experiments}

For all our models, we selected alignments by tuning for alignment F-score on a validation set of $460$ hand-aligned Czech-English and $1102$ Chinese-English sentences. $5$ iterations of Model~1 followed by $5$ iterations of the HMM alignment model produced better F-scores for ABA than $10$ iterations of each. For vanilla EM training, we tuned the number of model iterations $n$, and the threshold $\delta$ for alignment F-score using both decoding approaches \textbf{D1} and \textbf{D2} and found that \textbf{D2} worked the best. We carried out the same optimization strategy for PAT, in addition to tuning the regularization penalty $\lambda$, as well. We found $\lambda=300$ to work best for both models. For PAT on Chinese-English, \textbf{D1} with union gave us the best alignment F-score while \textbf{D2} produced slightly better F-scores for Czech-English. Table~\ref{tab:results} summarizes these results. 

We also tested the effect of alignments trained with PAT on translation quality, using a phrase based translation system, MOSES~\cite{koehn2007moses}\footnote{http://www.statmt.org/moses/}. The feature weights were trained discriminatively using MIRA \cite{chiang+alii:2008mira}, and we used a $5$-gram language model trained on the Xinhua portion of English Gigaword (LDC2007T07). For all other parameters, we used the default settings provided by the toolkit. The development data used for discriminative training were: for Chinese-English, data from the NIST 2004 and NIST 2006 test sets from the GALE program (LDC2006E92), and for Czech-English, we used $2051$ sentences from the WMT10 translation workshop. We used case-insensitive IBM \bleu{} (closest reference length) as our metric. 

On both language pairs, PAT performs significantly better than vanilla EM training, and compares favorably with ABA. The \bleu{} difference between PAT and ABA for Chinese-English is not statistically significant according to a bootstrap resampling significance test~\cite{koehn-stat:2004}. Training a translation model on combined alignments from ABA and PAT improved translation quality furthermore, achieving a $1.5$ \bleu{} point improvement on Chinese-English, suggesting that the two approaches might \marginpar{need to think of what to suggest here}. 