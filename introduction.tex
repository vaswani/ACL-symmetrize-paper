Alignment is a crucial subtask for many NLP problems: 
Word alignments are the backbone for extracting translation rules used in statistical machine translation; phoneme alignments are used to transliterate words from one language to another. 
Given two sequences of entities (e.g., words or phonemes), the goal is to find the best correspondence between the two sequences.

The most common models used in these tasks are both \emph{generative} and \emph{directed}; that is, they define a directed sequence of generation events by which one side (the source) produces the other (the target). 
% DC: I'm not sure what this example contributes at this point
%One typical generation event is entity-to-entity translation, parameterized by a translation table $t(\ve \mid \vf)$ that defines the probability of mapping a single source entity $\ve$ to a single target entity $\vf$ (for example, the IBM model translation table \cite{brown+alii:1993}).
%For example, the IBM 1 word alignment model\cite{brown+alii:1993} describes a stochastic process by which the target sentence is generated from the source sentence via word-for-word translation.
%
Considering that the underlying tasks are invertible, 
one could hope that training these models in both directions (source-to-target and target-to-source) would yield two models that agree. % on their model parameterization  and inferred alignments.
%Specifically, letting $t_1$ and $t_2$ denote the two models' entity-translation tables, we would expect that $t_1(\vf \mid \ve)$ is high if and only if $t_2(\ve \mid \vf)$ is high. 
However, this is typically not the case, and this leads to some problems.

For one, the model's directionality imposes restrictions on the inference space: in the IBM word alignment models, each target word can align to at most one source word, which may not be appropriate for some language pairs (for example, German compound target words usually arise from multiple English source words). 
To remedy this, we often resort to ad-hoc techniques, such as grow-diag-final-and \cite{koehn+:2003}, that heuristically combine alignments in two directions.
While this post-processing resolves some problems, it does not address the core problem -- unsupervised independent training of each model may very well lead to two local maxima that diverge in their parameters and ultimately their inferences.

A second fundamental problem with training alignment models is the dependence on parallel data.
In word alignment, most available parallel data is limited to a small number of languages.
Acquiring parallel data beyond these languages, or for tasks other than word alignment, remains a challenging task.
For example, to train their phoneme alignment model \newcite{KG98} manually assembled thousands of parallel English-Japanese terms. 
%\newcite{KG98} manually collected thousands of parallel English-Japanese sequences to train their phoneme alignment model. 


%For example, in \newcite{KG98}, the authors use (some number) \marginpar{insert number} of parallel English-Katana sequences to training phoneme alignment models. While large amounts of parallel data needed for word alignment is readily available for many language pairs, acquiring parallel phoneme sequences for transliteration can be very challenging. 

%There has been previous work on solving the problem of model disagreement \cite{liang+:2006:align} (ABA), and training phoneme alignment models with monolingual data \cite{RK09}. 
Previous work attacked the problems of model disagreement and parallel data dependency separately.
\newcite{liang+:2006:align} suggest an approach they call Alignment by Agreement (ABA) that jointly trains the two directional models by maximizing their individual data likelihoods while encouraging inference agreement.
%\newcite{liang+:2006:align} suggest an approach they call Alignment by Agreement (ABA) that jointly trains the two directional models, each maximizing its own data likelihood (as would be done independently) as well as a model coupling term that encodes a measure of agreement between the models.
Specifically, they introduce a model coupling term that rewards agreement between the alignment posteriors of each parallel sentence pair.
%By relying on posterior agreement, their approach further exploits the observed parallel training data by rewarding similarity between the two alignment posteriors (one for each direction) computed on each training sentence pair. 
Although their optimization procedure is inexact,\marginpar{DC: I'm still not sure what this means} their experimental results demonstrate the effectiveness of jointly training bi-directional models.
%and show that training with posterior agreement leads to better performing models (reduced AER). 
However, the dependence of their coupling term on both posteriors  limits their joint alignment approach to the parallel data setting only.
%However, their joint alignment approach cannot be applied beyond the parallel data setting.
%However, their approach cannot be applied to training alignment models without parallel data. 

\newcite{RK09} train English-to-Japanese transliteration models where only Japanese data is observed. Unfortunately, the resulting model considerably underperforms compared to the same model trained on parallel data.

In this paper, we present Parameter Agreement Training (PAT), a method for jointly training (directional) generative models that can be applied even without parallel data.
Compared to ABA, our approach (Section \ref{sec:method}) operates with a different measure of agreement; one that encourages similarity between the two models' parameter values and thereby (hopefully) reflects the invertibility of the underlying task.
%The general idea can be easily illustrated in the word alignment setting: Consider the two directional word alignment models' translation tables.  
%For any pair of words $e$ and $f$, it seems reasonable that $t(f \mid e)$ is high if and only if $t(e \mid f)$ is high. 
%This intuition follows simply since word translation is generally invertible.

Our resulting objective function can be efficiently optimized using EM \newcite{Dempster:1977}, where the E-step remains unchanged and the M-step reduces to an instance of convex programming. 
%% TL: NOTE TO SELF - WE ALREADY SAID THAT
%Furthermore, since our agreement measure does not depend on observed data, it can be applied in non-parallel data settings.

Using PAT, we are able to improve over the transliteration model of \newcite{RK09}, achieving significant reductions in back-transliteration error rates and bringing results closer to parallel-data trained model.
For word alignment, our results compare favorably with results from previous approaches for model agreement (TODO: add real numbers)

%\iffalse
%Many tasks in machine translation (MT) are first approached by modeling the transfer of information from one language to another (say, English to French). 
%The resulting directional models often follow a simple generative story that explains how source language entities could have generate corresponding target language entities. 
%For example, the IBM word alignment models \cite{Brown1993} explain how strings composing an English sentence can be translated and rearranged (distorted) into strings composing a French sentence and pronunciation Finite State Transducer (FST) can be used to explain how names in English undergo phonetic changes as they are uttered in French.
%
%However, the directionality may come with a price, as it impose restriction on the inference space - in the word alignment models (IBM 1 or 2 and HMM), only one-to-many word alignments (target to source) are possible, which may not fit well for some language pairs (for example, German compound target words usually arise from multiple English source words). 
%For this reason, it is common practice to produce word alignment inferences using models trained in both directions and then apply a post-processing symmetrization technique (such as grow-diag-final-and).
%However, while post-processing resolves some of the problems, independent training can still lead the two models to divergent local maxima; ones whose disagreeing inferences cannot be fixed by post-processing techniques.
%
%In Alignment by Agreement (ABA), Liang et al. (2006) suggest to jointly train the two directional models, each maximizing its own data likelihood (as would be done independently) as well as a model coupling term that encodes some measure of agreement between the models.
%Their suggested agreement measure further exploits the observed parallel training data by rewarding similarity between the two alignment posteriors (one for each direction) computed on each training sentence pair.
%Indeed, their experimental results show that training with posterior agreement leads to better performing models (reduced AER). At the same time however, the ABA formulation cements the dependency on parallel data thus limiting the applicability of their method to other settings.
%
%In this paper, we present Parameter Agreement Training (PAT); a method that operates with a different measure of agreement in mind (Section \ref{sec:model}))
%Remaining in context of word alignment (as we have so far), the general idea is as follows: Consider the two directional word alignment models' translation tables. 
%For any bilingual pair of words $e$ and $f$, it seems reasonable that $t(f \mid e)$ is high/low whenever $t(e \mid f)$ is high/low.
%This intuition follows simply since word translation is generally invertible \footnote{The word $e$ should be in the set of translations of the translation of $e$}.
%With the above in mind, we designed an agreement measure that encourages agreement in the two directional models parameters magnitudes.
%Our resulting objective function can be optimized using EM, where the E-step remains unchanged and the M-step reduces to an instance of convex programming.
%
%Furthermore, our new agreement measure is free of the parallel data dependency which in turn broadens the range of settings our method can be applied to beyond conventional word alignment.
%In particular, our method can be applied in the challenging decipherment setting, under which no parallel data is provided.
%
%We conduct two sets of experiments (Section \ref{bla}): (1) Our word alignment experiments (with parallel data) show comparable F- and BLEU score improvements to those of ABA on various language pairs.
%Combining the phrase-tables of both ABA and PAT leads to further increase in BLEU score.
%(2) In the decipherment settings (without parallel data) we repeat the Japanese to English back-transliteration experiments as described by Ravi and Knight (2009?). 
%PAT nearly splits the difference between the baseline (Ravi and Knight's formulation) and a method trained using parallel data. 
%Finally, ... ?
%\fi

\section{David's version}

%$\ldots$and ultimately their inferences.

In this paper, we present Parameter Agreement Training (PAT), a method for jointly training (directional) generative models.
Our approach (Section \ref{sec:method}) encourages similarity between the two models' parameter values and thereby (hopefully) reflects the invertibility of the underlying task. Our resulting objective function can be efficiently optimized using EM \cite{Dempster:1977}, where the E-step remains unchanged and the M-step reduces to an instance of convex programming.

\newcite{liang+:2006:align} suggest an approach they call Alignment by Agreement (ABA) that jointly trains the two directional models by maximizing their individual data likelihoods as well as a model coupling term that rewards agreement between the alignment posteriors of each parallel sentence pair.
Although their optimization procedure is inexact, their experimental results demonstrate the effectiveness of jointly training bi-directional models.
However, the dependence of their coupling term on both posteriors means that their approach only works on parallel data.

By contrast, one of the advantages of our method is that it works on non-parallel data as well.
In word alignment, most available parallel data is limited to a small number of languages, and acquiring parallel data beyond these languages, or for tasks other than word alignment, remains a challenging task. Therefore, recent work has begun to explore the use of non-parallel data. \newcite{RK09} train English-to-Japanese transliteration models where only Japanese data is observed. Unfortunately, the resulting model considerably underperforms compared to the same model trained on parallel data. But using PAT, we are able to reduce the whole-name error rate relative to the parallel-data trained model by 33\%.

On Czech-English and Chinese-English word alignment, 
we obtain improvements in alignment accuracy by up to 6.3 F1 points, 
and improvements in translation accuracy of up to 0.5 \bleu, 
both comparable to the improvements obtained by ABA. 
Interestingly, the improvements are nearly additive: 
by combining our alignments with those from ABA, we obtain a total improvement of 0.8-1.5 \bleu.


