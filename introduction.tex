Word alignment is an important part of any statistical translation pipeline. The most widely used word alignment models are the the IBM \cite{brown+alii:1993} and HMM \cite{vogel+alii:1996} models. These models describe a generative process by which the source sentence ($E$) generates the target sentence ($F$) via one-to-many alignments. The models are trained independently in each direction, and at test time, the alignments from both directions are \emph{symmetrized} using heuristics like \emph{grow-diag-final} \cite{och+ney:2003}. Although symmetrization corrects some of the mistakes that the independently trained models make, \newcite{liang+:2006:align} and \newcite{ganchev2010posterior} show that word alignment quality be improved when the models are trained jointly to agree on their inferences. However, the method of \newcite{liang+:2006:align} relies on parallel data, which might not always be the available, for example, in unsupervised transliteration with non-parallel data \cite{RK09}. Another method, posterior regularization \cite{ganchev2010posterior}, can be expensive, making it difficult to scale to large data. In this paper, we present an approach that improves unsupervised transliteration quality (section~\ref{sec:transliteration}) over a state-of-the-art baseline by jointly training English-Japanese and Japanese-English transliteration models on non-parallel data. Unlike the methods of \newcite{liang+:2006:align} and \newcite{ganchev2010posterior}, our approach encourages agreement in the parameters of the models (sections \ref{sec:background} and \ref{sec:method}). We also apply our procedure on joint training of word alignment models (section ~\ref{sec:alignment}) and we achieve results comparable to those of \newcite{liang+:2006:align} on multiple language pairs. 

\iffalse
predictions by symmetrization increases the overall predictive performance.
Several papers address this issue directly by jointly training these
asymmetric models with a particular notion of agreement in mind {[}reference{]}.
Generally speaking, these techniques encourage the two models to agree
on their inferences (posteriors) either on each sentence pair individually,
or over all sentence pairs together.

{[}{[}However, agreement on inference essentially treats the two models
themselves as black-boxes{]}{]}

In this paper, we explore a different type of model agreement we call
parameter agreement... (needs more content)

\fi