Many tasks in machine translation (MT) are first approached by modeling the transfer of information from one language to another (say, English to French). 
The resulting directional models often follow a simple generative story that explains how source language entities could have generate corresponding target language entities. 
For example, the IBM word alignment models \cite{Brown1993} explain how strings composing an English sentence can be translated and rearranged (distorted) into strings composing a French sentence and pronunciation Finite State Transducer (FST) can be used to explain how names in English undergo phonetic changes as they are uttered in French.

However, the directionality may come with a price, as it impose restriction on the inference space - in the word alignment models (IBM 1 or 2 and HMM), only one-to-many word alignments (target to source) are possible, which may not fit well for some language pairs (for example, German compound target words usually arise from multiple English source words). 
For this reason, it is common practice to produce word alignment inferences using models trained in both directions and then apply a post-processing symmetrization technique (such as grow-diag-final-and).
However, while post-processing resolves some of the problems, independent training can still lead the two models to divergent local maxima; ones whose disagreeing inferences cannot be fixed by post-processing techniques.

In Alignment by Agreement (ABA), Liang et al. (2006) suggest to jointly train the two directional models, each maximizing its own data likelihood (as would be done independently) as well as a model coupling term that encodes some measure of agreement between the models.
Their suggested agreement measure further exploits the observed parallel training data by rewarding similarity between the two alignment posteriors (one for each direction) computed on each training sentence pair.
Indeed, their experimental results show that training with posterior agreement leads to better performing models (reduced AER). At the same time however, the ABA formulation cements the dependency on parallel data thus limiting the applicability of their method to other settings.

In this paper, we present Parameter Agreement Training (PAT); a method that operates with a different measure of agreement in mind (Section \ref{sec:model}))
Remaining in context of word alignment (as we have so far), the general idea is as follows: Consider the two directional word alignment models' translation tables. 
For any bilingual pair of words $e$ and $f$, it seems reasonable that $t(f \mid e)$ is high/low whenever $t(e \mid f)$ is high/low.
This intuition follows simply since word translation is generally invertible \footnote{The word $e$ should be in the set of translations of the translation of $e$}.
With the above in mind, we designed an agreement measure that encourages agreement in the two directional models parameters magnitudes.
Our resulting objective function can be optimized using EM, where the E-step remains unchanged and the M-step reduces to an instance of convex programming.

Furthermore, our new agreement measure is free of the parallel data dependency which in turn broadens the range of settings our method can be applied to beyond conventional word alignment.
In particular, our method can be applied in the challenging decipherment setting, under which no parallel data is provided.

We conduct two sets of experiments (Section \ref{bla}): (1) Our word alignment experiments (with parallel data) show comparable F- and BLEU score improvements to those of ABA on various language pairs.
Combining the phrase-tables of both ABA and PAT leads to further increase in BLEU score.
(2) In the decipherment settings (without parallel data) we repeat the Japanese to English back-transliteration experiments as described by Ravi and Knight (2009?). 
PAT nearly splits the difference between the baseline (Ravi and Knight's formulation) and a method trained using parallel data. 
Finally, ... ?



%%%% old introduction
%Word alignment is an important part of any statistical translation pipeline. The most widely used word alignment models are the the IBM \cite{brown+alii:1993} and HMM \cite{vogel+alii:1996} models. These models describe a generative process by which the source sentence ($E$) generates the target sentence ($F$) via one-to-many alignments. The models are trained independently in each direction, and at test time, the alignments from both directions are \emph{symmetrized} using heuristics like \emph{grow-diag-final} \cite{och+ney:2003}. Although symmetrization corrects some of the mistakes that the independently trained models make, \newcite{liang+:2006:align} and \newcite{ganchev2010posterior} show that word alignment quality be improved when the models are trained jointly to agree on their inferences. However, the method of \newcite{liang+:2006:align} relies on parallel data, which might not always be the available, for example, in unsupervised transliteration with non-parallel data \cite{RK09}. Another method, posterior regularization \cite{ganchev2010posterior}, can be expensive, making it difficult to scale to large data. In this paper, we present an approach that improves unsupervised transliteration quality (section~\ref{sec:transliteration}) over a state-of-the-art baseline by jointly training English-Japanese and Japanese-English transliteration models on non-parallel data. Unlike the methods of \newcite{liang+:2006:align} and \newcite{ganchev2010posterior}, our approach encourages agreement in the parameters of the models (sections \ref{sec:background} and \ref{sec:method}). We also apply our procedure on joint training of word alignment models (section ~\ref{sec:alignment}) and we achieve results comparable to those of \newcite{liang+:2006:align} on multiple language pairs. 
%
%\iffalse
%predictions by symmetrization increases the overall predictive performance.
%Several papers address this issue directly by jointly training these
%asymmetric models with a particular notion of agreement in mind {[}reference{]}.
%Generally speaking, these techniques encourage the two models to agree
%on their inferences (posteriors) either on each sentence pair individually,
%or over all sentence pairs together.
%
%{[}{[}However, agreement on inference essentially treats the two models
%themselves as black-boxes{]}{]}
%
%In this paper, we explore a different type of model agreement we call
%parameter agreement... (needs more content)
%
%\fi