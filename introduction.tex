%\iffalse
%Many tasks in machine translation (MT) are first approached by modeling the transfer of information from one language to another (say, English to French). 
%The resulting directional models often follow a simple generative story that explains how source language entities could have generate corresponding target language entities. 
%For example, the IBM word alignment models \cite{Brown1993} explain how strings composing an English sentence can be translated and rearranged (distorted) into strings composing a French sentence and pronunciation Finite State Transducer (FST) can be used to explain how names in English undergo phonetic changes as they are uttered in French.
%
%However, the directionality may come with a price, as it impose restriction on the inference space - in the word alignment models (IBM 1 or 2 and HMM), only one-to-many word alignments (target to source) are possible, which may not fit well for some language pairs (for example, German compound target words usually arise from multiple English source words). 
%For this reason, it is common practice to produce word alignment inferences using models trained in both directions and then apply a post-processing symmetrization technique (such as grow-diag-final-and).
%However, while post-processing resolves some of the problems, independent training can still lead the two models to divergent local maxima; ones whose disagreeing inferences cannot be fixed by post-processing techniques.
%
%In Alignment by Agreement (ABA), Liang et al. (2006) suggest to jointly train the two directional models, each maximizing its own data likelihood (as would be done independently) as well as a model coupling term that encodes some measure of agreement between the models.
%Their suggested agreement measure further exploits the observed parallel training data by rewarding similarity between the two alignment posteriors (one for each direction) computed on each training sentence pair.
%Indeed, their experimental results show that training with posterior agreement leads to better performing models (reduced AER). At the same time however, the ABA formulation cements the dependency on parallel data thus limiting the applicability of their method to other settings.
%
%In this paper, we present Parameter Agreement Training (PAT); a method that operates with a different measure of agreement in mind (Section \ref{sec:model}))
%Remaining in context of word alignment (as we have so far), the general idea is as follows: Consider the two directional word alignment models' translation tables. 
%For any bilingual pair of words $e$ and $f$, it seems reasonable that $t(f \mid e)$ is high/low whenever $t(e \mid f)$ is high/low.
%This intuition follows simply since word translation is generally invertible \footnote{The word $e$ should be in the set of translations of the translation of $e$}.
%With the above in mind, we designed an agreement measure that encourages agreement in the two directional models parameters magnitudes.
%Our resulting objective function can be optimized using EM, where the E-step remains unchanged and the M-step reduces to an instance of convex programming.
%
%Furthermore, our new agreement measure is free of the parallel data dependency which in turn broadens the range of settings our method can be applied to beyond conventional word alignment.
%In particular, our method can be applied in the challenging decipherment setting, under which no parallel data is provided.
%
%We conduct two sets of experiments (Section \ref{bla}): (1) Our word alignment experiments (with parallel data) show comparable F- and BLEU score improvements to those of ABA on various language pairs.
%Combining the phrase-tables of both ABA and PAT leads to further increase in BLEU score.
%(2) In the decipherment settings (without parallel data) we repeat the Japanese to English back-transliteration experiments as described by Ravi and Knight (2009?). 
%PAT nearly splits the difference between the baseline (Ravi and Knight's formulation) and a method trained using parallel data. 
%Finally, ... ?
%\fi

Alignment is a crucial subtask for many larger NLP problems: Word alignments are the backbone for extracting translation rules used in statistical machine translation; phoneme alignments are used to transliterate words from one language to another. 
The goal is to align entities (e.g., words, phonemes) between two sequence, for example English and French sentences, or English phonemes and Japanese phonemes.

The popular models used in these tasks are both \emph{generative} and \emph{directed}, that is, they define a directed sequence of generation events by which one side of the pair (the source) produces the other (the target). 
For example, the IBM models for word alignment \newcite{brown+alii:1993} describe a stochastic process by which the target sentence is generated from the source sentence via reordering and word-for-word translation.

However, this directionality may come with a price as it imposes restrictions on the inference space - in the word alignment models (IBM 1, 2 and HMM), only one-to-many word alignments (target to source) are possible, which may not fit well for some language pairs (for example, German compound target words usually arise from multiple English source words). 
To remedy this, we often resort to ad-hoc alignment symmetrization techniques, such as grow-diag-final-and \cite{koehn+:2003}, \emph{after} training. 
%However, w
While post-processing resolves some of the problems, independent training can still lead the two models to divergent local maxima; ones whose disagreeing inferences cannot be fixed by post-processing techniques. 

A second problem with training alignment models is the dependence on parallel data.
In word alignment, most of the readily available parallel data is limited to European languages or specific languages of interest. 
Acquiring parallel data beyond these languages, or for tasks other than word alignment remains a challenging task.
For example, in \newcite{KG98}, the authors manually collected thousands \marginpar{insert number} of parallel English-Japanese sequences to training their phoneme alignment model. 

%For example, in \newcite{KG98}, the authors use (some number) \marginpar{insert number} of parallel English-Katana sequences to training phoneme alignment models. While large amounts of parallel data needed for word alignment is readily available for many language pairs, acquiring parallel phoneme sequences for transliteration can be very challenging. 

%There has been previous work on solving the problem of model disagreement \cite{liang+:2006:align} (ABA), and training phoneme alignment models with monolingual data \cite{RK09}. 
Previous work attacked the problems of model disagreement and parallel data dependency separately.
\newcite{liang+:2006:align} suggest an approach they call Alignment by Agreement (ABA) that jointly trains the two directional models, each maximizing its own data likelihood (as would be done independently) as well as a model coupling term that encodes a measure of agreement between the models. 
Their suggested agreement measure further exploits the observed parallel training data by rewarding similarity between the two alignment posteriors (one for each direction) computed on each training sentence pair. 
Indeed, even though their optimization procedure ultimately does not optimize a clear objective function, their experimental results (reduced AER) demonstrate the effectiveness in jointly training the two models.
%and show that training with posterior agreement leads to better performing models (reduced AER). 
However, their joint alignment approach cannot be applied beyond the parallel data setting.
%However, their approach cannot be applied to training alignment models without parallel data. 

In \cite{RK09} the authors train English-to-Japanese transliteration models in the decipherment setting  - that is, using monolingual (Japanese) data only.
Unfortunately, the resulting model considerably underperforms when compared to the same model trained on parallel data.

%For phoneme alignment,  alleviate the reliance on parallel data and improve monolingual alignment quality over the baseline, but their approach does not encourage model agreement, which can further improve alignment accuracy, as we will show in section~\ref{sec:results}. 

In this paper, we present Parameter Agreement Training (PAT); a method for jointly training (directional) generative models that can be applied even without parallel data.
Compared to ABA, our approach operates with a different measure of agreement in mind (Section \ref{sec:model})).
The general idea can be easily illustrated in the word alignment setting: Consider the two directional word alignment models' translation tables.  
For any pair of words $e$ and $f$, it seems reasonable that $t(f \mid e)$ is high(low) whenever $t(e \mid f)$ is high(low). 
This intuition follows simply since word translation is generally invertible \footnote{The word $e$ should be in the set of translations of the translation of $e$}.

%With the above in mind, we design an agreement measure that encourages agreement in the magnitudes of the parameters of the models in each direction.
With the above in mind, we designed an agreement measure that encourages both models to agree on the magnitude of their parameters.
Our resulting objective function can be efficiently optimized using EM, where the E-step remains unchanged and the M-step reduces to an instance of convex programming. 
Furthermore, since our agreement measure does not depend on the observed data (only on the model parameters), it can be applied in non-parallel data settings.
% such as unsupervised phoneme alignment with monolingual data. 

Using PAT, we are able to improve over the transliteration model of \cite{RK09}, achieving significant reductions in back-transliteration error rates and bringing results closer to parallel-data trained model.
For word alignment, our results compare favorably with results from previous approaches for model agreement (TODO: add real numbers)

%The generative process for word alignment allows a target word to align to \emph{at most} one source word, producing different alignments in the source-target vs target-source directions.
