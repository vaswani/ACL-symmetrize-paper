%
% File acl2014.tex
%
% Contact: koller@ling.uni-potsdam.de, yusuke@nii.ac.jp
%%
%% Based on the style files for ACL-2013, which were, in turn,
%% Based on the style files for ACL-2012, which were, in turn,
%% based on the style files for ACL-2011, which were, in turn, 
%% based on the style files for ACL-2010, which were, in turn, 
%% based on the style files for ACL-IJCNLP-2009, which were, in turn,
%% based on the style files for EACL-2009 and IJCNLP-2008...

%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt]{article}
\usepackage{acl2014}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
%\DeclareMathOperator*{\argmax}{arg\,max}
%\DeclareMathOperator*{\argmin}{arg\,min}

\usepackage{graphicx}



%\setlength\titlebox{5cm}

% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.
%\input{defs}

\title{Parameter Agreement Training with and without Parallel Data}

%\author{First Author \\
%  Affiliation / Address line 1 \\
%  Affiliation / Address line 2 \\
%  Affiliation / Address line 3 \\
%  {\tt email@domain} \\\And
%  Second Author \\
%  Affiliation / Address line 1 \\
%  Affiliation / Address line 2 \\
%  Affiliation / Address line 3 \\
%  {\tt email@domain} \\}
%\date{}

\input{math_definition.tex}

\begin{document}
\maketitle
\begin{abstract}
%% this doesn't make a lot of sense
%We present a simple approach that encourages jointly trained conditional models to agree on their parameter values. In contrast to methods that encourage agreement on inferences, our method can be applied in a wider range of settings.
%We demonstrate that our method, called parameter agreement training, leads to state-of-the-art accuracies on word alignment, and significantly improves accuracy on back-transliteration with no parallel data -- almost halving the difference between the previous best method and using parallel data.

\end{abstract}

\section{Introduction}
\label{sec:introduction}
\input{introduction.tex}

\section{Background}
\label{sec:background}
\input{background.tex}

\section{Parameter Agreement Training}
\label{sec:method}
\input{method.tex}


\section{Transliteration}
\label{sec:transliteration}
\input{transliteration.tex}

\section{Word Alignment}
\label{sec:alignment}
\input{alignment.tex}

\section{Conclusion}
We have presented Parameter Agreement Training (PAT) - an approach for jointly training two conditional models that encourages agreement on parameter values.
We derived an optimization procedure based on the EM framework, and argued that it is efficiently solvable due to the concavity of our agreement regularizer.
In contrast to previous work on agreement training, we have demonstrated that our approach can be successfully applied even without parallel data.


\bibliographystyle{acl2014}
\bibliography{thesis}

\end{document}
