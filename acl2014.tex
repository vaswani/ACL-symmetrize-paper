%
% File acl2014.tex
%
% Contact: koller@ling.uni-potsdam.de, yusuke@nii.ac.jp
%%
%% Based on the style files for ACL-2013, which were, in turn,
%% Based on the style files for ACL-2012, which were, in turn,
%% based on the style files for ACL-2011, which were, in turn, 
%% based on the style files for ACL-2010, which were, in turn, 
%% based on the style files for ACL-IJCNLP-2009, which were, in turn,
%% based on the style files for EACL-2009 and IJCNLP-2008...

%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt]{article}
\usepackage{acl2014}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
%\DeclareMathOperator*{\argmax}{arg\,max}
%\DeclareMathOperator*{\argmin}{arg\,min}

\usepackage{graphicx}



%\setlength\titlebox{5cm}

% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.
%\input{defs}

\title{Parameter Agreement Training with and without Parallel Data}
%{Joint Training of Alignment Models: with and without Parallel Data}


%\author{First Author \\
%  Affiliation / Address line 1 \\
%  Affiliation / Address line 2 \\
%  Affiliation / Address line 3 \\
%  {\tt email@domain} \\\And
%  Second Author \\
%  Affiliation / Address line 1 \\
%  Affiliation / Address line 2 \\
%  Affiliation / Address line 3 \\
%  {\tt email@domain} \\}
%\date{}

\input{math_definition.tex}

\begin{document}
\maketitle
\begin{abstract}
Learning how to align sequences is a prevalent problem in machine translation and NLP.  
State of the art approaches model alignment as a directed generative process by which an observed target sequence arises from an observed source sequence.
We propose an unsupervised approach for jointly learning such directed alignment models by means of maximizing their data likelihood and a measure of model agreement.  
Contrary to a previous approach (Alignment by Agreement), our method is applicable even without parallel data (i.e., decipherment).
We test our method on two different tasks - word alignment (with parallel data) and English-to-Japanese back-transliteration (without parallel data).
On Czech-to-English word alignment, we obtain +0.4pts BLEU compared to GIZA++ alignments. A simple phrase tables combination with a competitive alignment model further gain additional +0.4pts BLEU.
On the back-transliteration task, our method learns sparser models that are able to obtain significant reductions in whole name error rates, substantially reducing the gap between decipherment and parallel-data trained models by 33\%.
\end{abstract}

\section{Introduction}
\label{sec:introduction}
\input{introduction.tex}

\section{Background}
\label{sec:background}
\input{background.tex}

\section{Parameter Agreement Training}
\label{sec:method}
\input{method.tex}


\section{Deciphering Transliteration}
\label{sec:transliteration}
\input{transliteration.tex}

\section{Word Alignment}
\label{sec:alignment}
\input{alignment.tex}

\section{Related Work}
\input{related.tex}

\section{Conclusion}
We have presented Parameter Agreement Training (PAT) - an approach for jointly training two conditional models that encourages agreement on parameter values.
We derived an optimization procedure based on the EM framework, and argued that it is efficiently solvable due to the concavity of our agreement regularizer.
In contrast to previous work on agreement training, we have demonstrated that our approach can be successfully applied even without parallel data.
\bibliographystyle{acl}
\bibliography{thesis}

\end{document}

%%%% old content of abstract / introduction
%	\iffalse
%% this doesn't make a lot of sense
%We present a simple approach that encourages jointly trained conditional models to agree on their parameter values. In contrast to methods that encourage agreement on inferences, our method can be applied in a wider range of settings.
%We demonstrate that our method, called parameter agreement training, leads to state-of-the-art accuracies on word alignment, and significantly improves accuracy on back-transliteration with no parallel data -- almost halving the difference between the previous best method and using parallel data.

%Alignment is a crucial subtask for many larger NLP problems: Word alignments are the backbone for extracting translation rules used in statistical machine translation; phoneme alignments are used to transliterate Japanese katakana to English and vice-versa. The goal is to align entities, which could be words or phonemes, between two sequences, which could be pairs of source and target sentences or pairs of phoneme sequences. The popular models used in these tasks are both \emph{generative} and \emph{directed}, that is, they define a directed sequence of events by which one side of the pair produces the other side. For example, the IBM models for word alignment \newcite{brown+alii:1993} describe a stochastic process by which the target sentence is generated from the source sentence via word alignments. These processes can sometimes produce different alignments, depending on the direction of generation. The generative process for word alignment allows a target word to align to \emph{at most} one source word, producing different alignments in the source-target vs target-source directions. Additionally, the models in each direction are typically trained independently of each other. As a result, they disagree on the alignments they predict and different errors can arise in each direction. To remedy this, we resort to ad-hoc alignment symmetrization approaches \cite{koehn+:2003} \emph{after} training. A second problem for training alignment models is the need for parallel data. For example, in \newcite{KG98}, the authors use (some number) \marginpar{insert number} of parallel English-Katana sequences to training phoneme alignment models. While large amounts of parallel data needed for word alignment is readily available for many language pairs, acquiring parallel phoneme sequences for transliteration can be very challenging. 
%
%There has been previous work on solving the problem of model disagreement in word alignment \cite{liang+:2006:align} and training phoneme alignment models from large amounts of monolingual data~\cite{RK09}. However, they do not optimize a clear objective function and their approach cannot be applied to training alignment models without parallel data. ~\newcite{RK09} alleviate the reliance on parallel data and improve monolingual phoneme alignment over the baseline, but their approach does not encourage model agreement, which can improve alignment accuracy. In our paper, we present a \emph{single} approach that achieves both model agreement during training, and can be used in non-parallel settings. Our approach, \emph{Parameter Agreement Training}, encourages model agreement by adding a regularization term that penalizes disagreement between the (magnitudes of the ?) model parameters in each direction. Our regularizer is convex, allowing us to efficiently optimize the objective function with the EM algorithm. We apply our techniques to word alignment and phoneme alignment. Using our approach, we are able to significantly improve over \newcite{RK09}. In word alignment, our results compare favorably with results from previous approaches for model agreement.  
%\fi
